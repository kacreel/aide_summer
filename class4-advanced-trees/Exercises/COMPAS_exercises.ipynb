{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMPAS Recidivism Prediction Analysis - Exercise\n",
    "## Building and Evaluating Fair Machine Learning Models\n",
    "\n",
    "### Introduction\n",
    "In this exercise, you will analyze the COMPAS (Correctional Offender Management Profiling for Alternative Sanctions) dataset to:\n",
    "1. Build a recidivism prediction model\n",
    "2. Evaluate fairness across different demographic groups\n",
    "3. Compare different ML algorithms\n",
    "\n",
    "**What is recidivism?** Whether someone will commit another crime within 2 years\n",
    "\n",
    "**Your goal:** Build a model that predicts recidivism while considering fairness across racial groups\n",
    "\n",
    "### Dataset Information\n",
    "The COMPAS dataset contains criminal history data and risk assessments. Key columns include:\n",
    "- `two_year_recid`: Our target variable (0 = no recidivism, 1 = recidivated within 2 years)\n",
    "- `race`: Demographic information\n",
    "- Criminal history features: `juv_fel_count`, `juv_misd_count`, `juv_other_count`, `priors_count`\n",
    "- `decile_score`: COMPAS risk score (1-10, higher = higher risk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Building the Model\n",
    "\n",
    "### Step 1: Import Required Libraries\n",
    "Import all the necessary packages for this analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import required packages\n",
    "# You'll need: pandas, sklearn modules for decision trees, train_test_split, accuracy_score\n",
    "# Also import matplotlib.pyplot and seaborn for visualizations\n",
    "\n",
    "\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Load and Explore the Data\n",
    "Load the COMPAS dataset and explore its basic properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load the dataset 'compas-scores-two-years.csv'\n",
    "\n",
    "\n",
    "# TODO: Print the shape of the dataset and view the first few rows\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Clean the Data\n",
    "Clean the dataset according to the following criteria:\n",
    "1. Keep only cases where `days_b_screening_arrest` is between -30 and 30\n",
    "2. Remove cases where `is_recid` equals -1\n",
    "3. Remove traffic offenses (where `c_charge_degree` equals \"O\")\n",
    "4. Remove rows where `score_text` equals \"N/A\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Starting with {len(df)} records\")\n",
    "\n",
    "# TODO: Apply the four cleaning steps described above\n",
    "# Print the number of records after each step\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Final dataset: {len(df)} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Explore Key Variables\n",
    "Analyze the distribution of the target variable and demographic information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Calculate and print the distribution of two_year_recid\n",
    "# Show both counts and percentages\n",
    "\n",
    "\n",
    "# TODO: Show the distribution of races in the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Prepare Features and Target\n",
    "Select your features and target variable for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create X with these features: \"juv_fel_count\", \"juv_misd_count\", \"juv_other_count\", \"priors_count\"\n",
    "# Create y with the target: \"two_year_recid\"\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Print the shapes and show basic statistics of X\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6: Split Data for Training and Testing\n",
    "Create train and test sets with 70% for training and 30% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Split the data using train_test_split\n",
    "# Use test_size=0.3 and random_state=3\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Print the sizes of train and test sets\n",
    "# Also print the recidivism rates in each set\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7: Train a Decision Tree Model\n",
    "Train a decision tree classifier with max_depth=3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create and train a DecisionTreeClassifier\n",
    "# Use max_depth=3\n",
    "\n",
    "\n",
    "\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8: Make Predictions and Evaluate\n",
    "Make predictions on the test set and evaluate the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Make predictions on the test set\n",
    "\n",
    "\n",
    "# TODO: Calculate and print the accuracy\n",
    "\n",
    "\n",
    "# TODO: Create and display a confusion matrix\n",
    "# Hint: Use sklearn.metrics.confusion_matrix\n",
    "\n",
    "\n",
    "# TODO: Print the decision tree structure using export_text\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9: Compare with COMPAS\n",
    "Compare your model's predictions with the original COMPAS scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Convert COMPAS decile_score to binary (>5 means high risk = 1)\n",
    "\n",
    "\n",
    "# TODO: Get COMPAS predictions for the test set indices\n",
    "\n",
    "\n",
    "# TODO: Calculate the agreement between your model and COMPAS\n",
    "# Also compare the accuracy of both models\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Fairness Analysis\n",
    "\n",
    "### Understanding Fairness Metrics\n",
    "\n",
    "You will implement three fairness metrics:\n",
    "\n",
    "1. **Demographic Parity Difference**: Measures if all groups have similar positive prediction rates\n",
    "2. **False Positive Rate**: Rate of incorrectly predicting recidivism for people who don't actually reoffend\n",
    "3. **Equalized Odds Difference**: Measures if the model is equally accurate across groups\n",
    "\n",
    "### Step 1: Calculate Demographic Parity Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import demographic_parity_difference from fairlearn.metrics\n",
    "\n",
    "\n",
    "# TODO: Get race information for the test set\n",
    "\n",
    "\n",
    "# TODO: Calculate and print the demographic parity difference\n",
    "\n",
    "\n",
    "# Interpret the result - what does this value mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Analyze False Positive Rates\n",
    "Calculate the false positive rate for Black individuals and compare with the overall rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import false_positive_rate from fairlearn.metrics\n",
    "\n",
    "\n",
    "# TODO: Get race data for test set\n",
    "\n",
    "\n",
    "# TODO: Filter for Black/African-American individuals\n",
    "# Calculate FPR for this group\n",
    "\n",
    "\n",
    "# TODO: Calculate overall FPR\n",
    "\n",
    "\n",
    "# TODO: Print and compare the results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Implement Third Fairness Metric\n",
    "Choose and implement one additional fairness metric from fairlearn.\n",
    "\n",
    "Options include:\n",
    "- `equalized_odds_difference`\n",
    "- `true_positive_rate_difference`\n",
    "- `false_negative_rate_difference`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Choose and implement a third fairness metric\n",
    "# Import the metric, calculate it, and interpret the results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment with Model Parameters\n",
    "Try different max_depth values and see how they affect accuracy and fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Test max_depth values of 2, 3, and 5\n",
    "# For each, calculate accuracy and demographic parity difference\n",
    "# Which provides the best balance?\n",
    "\n",
    "for depth in [2, 3, 5]:\n",
    "    # TODO: Train model with this depth\n",
    "    \n",
    "    \n",
    "    # TODO: Calculate metrics\n",
    "    \n",
    "    \n",
    "    print(f\"\\nMax Depth = {depth}:\")\n",
    "    # TODO: Print results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Try Different Models\n",
    "\n",
    "Implement at least two different models from the following options:\n",
    "- Random Forest\n",
    "- Support Vector Machine (SVM)\n",
    "- K-Nearest Neighbors (KNN)\n",
    "- Logistic Regression\n",
    "\n",
    "### Model 1: [Choose Your Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import and implement your first alternative model\n",
    "# Train it, make predictions, and calculate accuracy and fairness metrics\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Print results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model 2: [Choose Your Model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Import and implement your second alternative model\n",
    "# Train it, make predictions, and calculate accuracy and fairness metrics\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Print results\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare All Models\n",
    "Create a summary comparing all the models you've trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a comparison table or visualization\n",
    "# Include at least: model name, accuracy, and one fairness metric\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Which model would you recommend and why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection Questions\n",
    "\n",
    "Answer the following questions based on your analysis:\n",
    "\n",
    "1. **Accuracy vs. Fairness**: Did you notice any trade-offs between model accuracy and fairness? Explain.\n",
    "\n",
    "2. **Feature Selection**: The model uses only criminal history features. What are the ethical implications of this choice?\n",
    "\n",
    "3. **Real-world Impact**: How might false positives and false negatives affect real people in the criminal justice system?\n",
    "\n",
    "4. **Improvements**: What changes would you suggest to make the model more fair while maintaining reasonable accuracy?\n",
    "\n",
    "### Your Answers:\n",
    "\n",
    "1. [Your answer here]\n",
    "\n",
    "2. [Your answer here]\n",
    "\n",
    "3. [Your answer here]\n",
    "\n",
    "4. [Your answer here]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus Challenges (Optional)\n",
    "\n",
    "If you finish early, try these additional challenges:\n",
    "\n",
    "1. **Feature Engineering**: Create new features (e.g., total juvenile offenses) and see if they improve the model\n",
    "\n",
    "2. **Visualization**: Create visualizations showing fairness metrics across different demographic groups\n",
    "\n",
    "3. **Additional Sensitive Features**: Analyze fairness with respect to age or sex\n",
    "\n",
    "4. **Cross-validation**: Implement cross-validation to get more robust performance estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Space for bonus challenges\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
