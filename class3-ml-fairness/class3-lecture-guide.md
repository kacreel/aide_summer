# Class 3: ML Fairness and Algorithmic Bias - Lecture Guide

## üìã Table of Contents
- [Overview](#overview)
- [Class Schedule](#class-schedule)
- [Learning Objectives](#learning-objectives)
- [Quick Links](#quick-links)

## Overview
Exploration of fairness in machine learning through hands-on analysis using Google's What-If Tool and the controversial COMPAS criminal risk assessment dataset.

## Class Schedule

### Session 1: What-If Tool Introduction (30 minutes)
**Understanding Algorithmic Fairness**
- **Tool:** [What-If Tool Tutorial](https://pair-code.github.io/what-if-tool/learn/tutorials/walkthrough/)
- **Demo:** [Census Dataset Walkthrough](https://pair-code.github.io/what-if-tool/demos/uci.html)
- Introduction to fairness concepts and bias detection
- Interactive model analysis techniques

### Session 2: COMPAS Dataset Analysis (40 minutes)
**Hands-on Bias Detection**
- **Tool:** [What-If Tool COMPAS Demo](https://pair-code.github.io/what-if-tool/demos/compas.html)
- **Worksheet:** [Analysis Worksheet](https://docs.google.com/document/d/1XRQTGwyYw6vZ4e2LGDVSM8BEfbxoY16BLYA5OnLF8O8/edit?usp=sharing)
- Analyze criminal risk assessment bias
- Explore fairness metrics and demographic disparities
- Document findings using structured analysis

### Session 3: Discussion & Implications (20 minutes)
**Critical Analysis**
- Share findings from COMPAS analysis
- Discuss real-world implications of biased algorithms
- Explore fairness-accuracy trade-offs

## Learning Objectives
Students will learn to:
- **Understand** algorithmic fairness concepts and bias sources
- **Use** Google's What-If Tool for interactive model analysis
- **Identify** bias patterns in criminal justice ML systems (COMPAS)
- **Analyze** fairness metrics across demographic groups
- **Evaluate** trade-offs between accuracy and fairness

## Key Concepts

| Concept | Description |
|---------|-------------|
| **Algorithmic Fairness** | Ensuring ML models don't discriminate against protected groups |
| **COMPAS** | Controversial criminal risk assessment tool used in US courts |
| **What-If Tool** | Google's interactive tool for ML model analysis and bias detection |
| **Bias Detection** | Methods for identifying unfair model behavior across demographics |
| **Fairness Metrics** | Quantitative measures of model fairness (equality of opportunity, etc.) |
| **Demographic Parity** | Equal positive prediction rates across all groups |
| **Equal Opportunity** | Equal true positive rates across protected groups |

## üîó Quick Links

### üìö Tools & Resources
| Resource | Description | Link |
|----------|-------------|------|
| What-If Tool Tutorial | Interactive census dataset walkthrough | [üîß Open Tutorial](https://pair-code.github.io/what-if-tool/learn/tutorials/walkthrough/) |
| Census Demo | Web-based What-If Tool demo | [üîß Open Demo](https://pair-code.github.io/what-if-tool/demos/uci.html) |
| COMPAS Analysis Tool | What-If Tool with COMPAS dataset | [üîß Open COMPAS Demo](https://pair-code.github.io/what-if-tool/demos/compas.html) |
| Analysis Worksheet | Structured analysis template | [üìù Google Doc](https://docs.google.com/document/d/1XRQTGwyYw6vZ4e2LGDVSM8BEfbxoY16BLYA5OnLF8O8/edit?usp=sharing) |

### üìñ Background Reading
- [Equivant Response to ProPublica](https://web.archive.org/web/20240624143309/https://www.equivant.com/response-to-propublica-demonstrating-accuracy-equity-and-predictive-parity/) - Industry perspective on COMPAS fairness (archived version)

### üóÇÔ∏è Navigation
- [‚Üê Back to Main Course](../README.md)
- [‚Üê Previous: Class 2 - Classification & Data](../class2-classification-data/class2-lecture-guide.md)
- [‚Üí Next: Class 4 - Advanced Trees](../class4-advanced-trees/class4-lecture-guide.md)


